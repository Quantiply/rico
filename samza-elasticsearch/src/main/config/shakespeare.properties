# Job
job.factory.class=org.apache.samza.job.local.ThreadJobFactory
job.name=shakespeare

# YARN
# yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-dist.tar.gz

#Custom
rico.schema.registry.url=http://localhost:9081
rico.es.index.prefix=shakespeare
rico.es.doc.type=lines
#Keep retrying until success
rico.drop.on.error=false

# Task
task.class=com.quantiply.samza.task.ESPushTask
task.inputs=kafka.shakespeare
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
# Normally, this would be 3, but we have only one broker.
task.checkpoint.replication.factor=1

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.sys.samza_metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Serializers
serializers.registry.byte.class=org.apache.samza.serializers.ByteSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Kafka System
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=byte
systems.kafka.samza.msg.serde=byte
#Serde for metrics topic
systems.kafka.streams.sys.samza_metrics.samza.msg.serde=metrics
#rhoover: when checkpoint is not present, read oldest data possible
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181/
systems.kafka.producer.bootstrap.servers=localhost:9092
systems.kafka.producer.compression.type=lz4
systems.kafka.producer.batch.size=262144
systems.kafka.producer.linger.ms=5

#Elasticsearch System
systems.es.samza.factory=com.quantiply.samza.system.elasticsearch.ElasticsearchSystemFactory
systems.es.http.host=localhost
systems.es.http.port=9200
systems.es.flush.interval.ms=1000
systems.es.flush.max.actions=10000
