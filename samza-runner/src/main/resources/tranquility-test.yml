tranquility:
  dataSource: "test1"
  aggregations:
    - name: "count"
      type: "count"

  timestampColumn: "timestamp"
  timeFormat: "auto"
  dimensions:
    - "bar"
    - "dim2"
  queryGranularity : "minute"
  windowPeriod: "PT1m"
  segmentGranularity: "minute"
  partitions: 3
  replicas: 1
  indexingService: "overlord"
  firehosePattern: "com.quantiply.druid:firehose:test-11:%s"
  discoveryPath: "/com.quantiply.druid/discovery"
  #zkConnectString: "fb-agg-overlord-0.demo-us-east-1b.quantezza.com"
  zkConnectString: "192.168.59.103"

samza:
  job.name: investor.demo.tranquility
  task.inputs: kafka.investor-demo
  task.output: kafka.errors
  systems.kafka.consumer.zookeeper.connect: 192.168.59.103:2181
  systems.kafka.consumer.auto.offset.reset: smallest
  systems.kafka.producer.metadata.broker.list: 192.168.59.103:9092
  processor.name: tranquility
  processor.class: TranquilityProcessor
  # Ignore bad JSON records for now.
  task.drop.deserialization.errors: "true"
  task.ignored.exceptions: org.codehaus.jackson.JsonParseException
